{
 "metadata": {
  "name": "",
  "signature": "sha256:9020824cc3a63410335e66a2e3ccdedb3c376096fdb57cc7e9d5ba65d6b30f2f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Assignment 3\n",
      "\n",
      "Author: Julie (Xiaoshu) Qiu\n",
      "\n",
      "Date: 8th March 2015"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Import data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "from sklearn import naive_bayes\n",
      "\n",
      "pd.set_option('display.width', 500)\n",
      "pd.set_option('display.max_columns', 30)\n",
      "\n",
      "critics = pd.read_csv('data/rt_critics.csv')\n",
      "critics.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>critic</th>\n",
        "      <th>fresh</th>\n",
        "      <th>imdb</th>\n",
        "      <th>publication</th>\n",
        "      <th>quote</th>\n",
        "      <th>review_date</th>\n",
        "      <th>rtid</th>\n",
        "      <th>title</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>        Derek Adams</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>       Time Out</td>\n",
        "      <td> So ingenious in concept, design and execution ...</td>\n",
        "      <td> 2009-10-04</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>    Richard Corliss</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>  TIME Magazine</td>\n",
        "      <td>                 The year's most inventive comedy.</td>\n",
        "      <td> 2008-08-31</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>        David Ansen</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>       Newsweek</td>\n",
        "      <td> A winning animated feature that has something ...</td>\n",
        "      <td> 2008-08-18</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>      Leonard Klady</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>        Variety</td>\n",
        "      <td> The film sports a provocative and appealing st...</td>\n",
        "      <td> 2008-06-09</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> Jonathan Rosenbaum</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td> Chicago Reader</td>\n",
        "      <td> An entertaining computer-generated, hyperreali...</td>\n",
        "      <td> 2008-03-10</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "               critic  fresh    imdb     publication                                              quote review_date  rtid      title\n",
        "0         Derek Adams  fresh  114709        Time Out  So ingenious in concept, design and execution ...  2009-10-04  9559  Toy story\n",
        "1     Richard Corliss  fresh  114709   TIME Magazine                  The year's most inventive comedy.  2008-08-31  9559  Toy story\n",
        "2         David Ansen  fresh  114709        Newsweek  A winning animated feature that has something ...  2008-08-18  9559  Toy story\n",
        "3       Leonard Klady  fresh  114709         Variety  The film sports a provocative and appealing st...  2008-06-09  9559  Toy story\n",
        "4  Jonathan Rosenbaum  fresh  114709  Chicago Reader  An entertaining computer-generated, hyperreali...  2008-03-10  9559  Toy story"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Given the text and classifier above, there is still **plenty** we can do to work through data cleanup and improve the model.\n",
      "\n",
      "1. Consider feature selection here: we haven't dropped a single feature! How could we evaluate this process? (check out `f_classif`)\n",
      "2. Last class we experiments with nltk and the part of speach tagger. Consider replacing words with parts of speach instead (using the default tagger), or other text processing tools (remove the stopwords... or just keep the stopwords!)\n",
      "3. What else is in the quote that we could identify and replace more easily?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Vectorizing with SK-Learn"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "CountVectorizer?\n",
      "vectorizer = CountVectorizer(ngram_range=(1,2)) \n",
      "\n",
      "rotten_vectorizer = vectorizer.fit(critics.quote) #going across all the quotes in the quote column\n",
      "x = vectorizer.fit_transform(critics.quote)  #refit & returns back our sparse matrix. \n",
      "y = (critics.fresh == 'fresh').values.astype(int) \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print x[0][0]\n",
      "x_back = x.toarray()\n",
      "\n",
      "test=pd.DataFrame(x_back, columns=vectorizer.get_feature_names()) #case insensitive\n",
      "test.head()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>000</th>\n",
        "      <th>000 000</th>\n",
        "      <th>000 and</th>\n",
        "      <th>000 leagues</th>\n",
        "      <th>000 looks</th>\n",
        "      <th>000 page</th>\n",
        "      <th>000 to</th>\n",
        "      <th>0014</th>\n",
        "      <th>0014 or</th>\n",
        "      <th>007</th>\n",
        "      <th>007 adventure</th>\n",
        "      <th>007 but</th>\n",
        "      <th>007 capers</th>\n",
        "      <th>007 formula</th>\n",
        "      <th>007 is</th>\n",
        "      <th>...</th>\n",
        "      <th>zorros</th>\n",
        "      <th>zorros two</th>\n",
        "      <th>zowie</th>\n",
        "      <th>zucker</th>\n",
        "      <th>zucker brother</th>\n",
        "      <th>zucker dutifully</th>\n",
        "      <th>zucker stops</th>\n",
        "      <th>zweibel</th>\n",
        "      <th>zweibel and</th>\n",
        "      <th>zwick</th>\n",
        "      <th>zwick intimate</th>\n",
        "      <th>zwick is</th>\n",
        "      <th>zzzzzs</th>\n",
        "      <th>zzzzzs in</th>\n",
        "      <th>zzzzzzzzz</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 163505 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "   000  000 000  000 and  000 leagues  000 looks  000 page  000 to  0014  0014 or  007  007 adventure  007 but  007 capers  007 formula  007 is    ...      zorros  zorros two  zowie  zucker  zucker brother  zucker dutifully  zucker stops  zweibel  zweibel and  zwick  zwick intimate  zwick is  zzzzzs  zzzzzs in  zzzzzzzzz\n",
        "0    0        0        0            0          0         0       0     0        0    0              0        0           0            0       0    ...           0           0      0       0               0                 0             0        0            0      0               0         0       0          0          0\n",
        "1    0        0        0            0          0         0       0     0        0    0              0        0           0            0       0    ...           0           0      0       0               0                 0             0        0            0      0               0         0       0          0          0\n",
        "2    0        0        0            0          0         0       0     0        0    0              0        0           0            0       0    ...           0           0      0       0               0                 0             0        0            0      0               0         0       0          0          0\n",
        "3    0        0        0            0          0         0       0     0        0    0              0        0           0            0       0    ...           0           0      0       0               0                 0             0        0            0      0               0         0       0          0          0\n",
        "4    0        0        0            0          0         0       0     0        0    0              0        0           0            0       0    ...           0           0      0       0               0                 0             0        0            0      0               0         0       0          0          0\n",
        "\n",
        "[5 rows x 163505 columns]"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Question 1 Consider feature selection here: we haven't dropped a single feature! How could we evaluate this process? (check out f_classif)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Feature selection based on pvalues"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sklearn\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "CountVectorizer?\n",
      "vectorizer = CountVectorizer(ngram_range=(1,2)) \n",
      "\n",
      "rotten_vectorizer = vectorizer.fit(critics.quote) #going across all the quotes in the quote column\n",
      "x = vectorizer.fit_transform(critics.quote)  #refit & returns back our sparse matrix. \n",
      "y = (critics.fresh == 'fresh').values.astype(int) \n",
      "\n",
      "f,p=sklearn.feature_selection.f_classif(x,y)\n",
      "print \"Eligible p-values based on columns: \"\n",
      "print p\n",
      "\n",
      "xbest=[]\n",
      "pbest=[]\n",
      "for i in range(len(p)):\n",
      "    if p[i] < .05:\n",
      "        pbest.append(p[i])\n",
      "        xbest.append(x[:,i])\n",
      " \n",
      "print \"Total features length\", len(critics.quote)\n",
      "print \"After feature selection, we are left with \", len(xbest), \"features.\"\n",
      "print \"Take a look at the sparse matrix of the features: \"\n",
      "print xbest[0]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Eligible p-values based on columns: \n",
        "[ 0.37952658  0.20909493  0.20909493 ...,  0.20909493  0.20909493\n",
        "  0.20909493]\n",
        "Total features length"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 14072\n",
        "After feature selection, we are left with  3003 features.\n",
        "Take a look at the sparse matrix of the features: \n",
        "  (1744, 0)\t1\n",
        "  (3837, 0)\t1\n",
        "  (6336, 0)\t1\n"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###How the model prediction has changed before & after feature selection\n",
      "using different regression method"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import linear_model\n",
      "from sklearn.feature_selection import SelectKBest\n",
      "from sklearn.feature_selection import chi2 #think of chi2 is similar to p value\n",
      "X_new = SelectKBest(chi2, k=20).fit_transform(x,y) #k is the column number\n",
      "\n",
      "\n",
      "def train_and_measure(classifier, x, y, tsize): #what's a classifier: bayes, MultinomialNB, logistic regression etc. \n",
      "    from sklearn import cross_validation\n",
      "    \"\"\"\n",
      "    Function accepts a classifer from sklearn and computes the accuracy measure for a random train and test split\n",
      "    classifier: an sklearn class\n",
      "    x         : a matrix of features\n",
      "    y         : a vector of targets\n",
      "    \"\"\"\n",
      "    xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(x, y, test_size=tsize, random_state=1234)\n",
      "    clf = classifier.fit(xtrain, ytrain) #passing the instance of this class. \n",
      "\n",
      "    #Print the accuracy on the test and training dataset\n",
      "    training_accuracy = clf.score(xtrain, ytrain)\n",
      "    test_accuracy = clf.score(xtest, ytest)\n",
      "    print classifier\n",
      "    print \"Accuracy on training data: %0.2f\" % (training_accuracy)\n",
      "    print \"Accuracy on test data:     %0.2f\" % (test_accuracy)\n",
      " \n",
      "print \"Before feature selection:\"\n",
      "print \n",
      "\n",
      "x_ones = (x >= 1)\n",
      "train_and_measure(naive_bayes.MultinomialNB(), x, y, 0.2)\n",
      "train_and_measure(naive_bayes.BernoulliNB(), x_ones, y, 0.2)\n",
      "train_and_measure(linear_model.LogisticRegression(), x, y, 0.2)\n",
      "\n",
      "print \"------------------------------------------------------------\"\n",
      "\n",
      "print \"After feature selection:\"\n",
      "print \n",
      "train_and_measure(naive_bayes.MultinomialNB(), X_new, y, 0.2)\n",
      "train_and_measure(naive_bayes.BernoulliNB(), X_new, y, 0.2)\n",
      "train_and_measure(linear_model.LogisticRegression(), X_new, y, 0.2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Before feature selection:\n",
        "\n",
        "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Accuracy on training data: 0.99\n",
        "Accuracy on test data:     0.76\n",
        "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Accuracy on training data: 0.88\n",
        "Accuracy on test data:     0.65\n",
        "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Accuracy on training data: 1.00\n",
        "Accuracy on test data:     0.75\n",
        "------------------------------------------------------------\n",
        "After feature selection:\n",
        "\n",
        "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
        "Accuracy on training data: 0.64\n",
        "Accuracy on test data:     0.62\n",
        "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
        "Accuracy on training data: 0.65\n",
        "Accuracy on test data:     0.62\n",
        "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Accuracy on training data: 0.65\n",
        "Accuracy on test data:     0.62\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As we can see from above, the accuracy % given by both training and test data have decreased after feature selection. However, the gap between accuracy on training and test has shrank by a significant amount, regardless of the regression model used. This means we are getting a more general and more applicable method after feature selection.  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Accuracy prediction using confusion Matrix. Feature selection based on \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from sklearn import cross_validation\n",
      "kfold = cross_validation.KFold(n=x_ones.shape[0], n_folds=5, shuffle=True, random_state=1234)\n",
      "\n",
      "train_acc = []\n",
      "test_acc = []\n",
      "for train_index, test_index in kfold:\n",
      "    clf = naive_bayes.MultinomialNB().fit(X_new[train_index], y[train_index])\n",
      "    train_acc.append(clf.score(X_new[train_index], y[train_index]))\n",
      "    test_acc.append(clf.score(X_new[test_index], y[test_index]))\n",
      "\n",
      "#x_back = xbest.toarray()\n",
      "#pd.DataFrame(xbest[0], columns=vectorizer.get_feature_names())\n",
      "\n",
      "clf = naive_bayes.MultinomialNB().fit(X_new[train_index], y[train_index])\n",
      "\n",
      "from sklearn.metrics import confusion_matrix\n",
      "from __future__ import division\n",
      "\n",
      "y_true = y #actual y values\n",
      "y_pred = clf.predict(X_new) #predicted y\n",
      "\n",
      "'''\n",
      "Note! the confusion matrix here will be [0 1],\n",
      "not [1, 0] as in the above image.\n",
      "'''\n",
      "conf = confusion_matrix(y_true, y_pred) #set confusion matrix \n",
      "\n",
      "print conf\n",
      "\n",
      "print clf.score(X_new, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[1067 4392]\n",
        " [ 699 7914]]\n",
        "0.638217737351\n"
       ]
      }
     ],
     "prompt_number": 75
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Question 2 Remove stopwords"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "import re\n",
      "\n",
      "def tokenize_quote(q, remove_stop=True):\n",
      "    import string\n",
      "    import re\n",
      "    quote = q\n",
      "    quote = quote.lower()\n",
      "    quote = quote.translate(string.maketrans(\"\",\"\"), string.punctuation)\n",
      "    quotes = nltk.tokenize.wordpunct_tokenize(quote)\n",
      "    \n",
      "    if remove_stop:\n",
      "        stopwords_filter = set(nltk.corpus.stopwords.words('english'))\n",
      "        quotes = [quote for quote in quotes if quote not in stopwords_filter]\n",
      "\n",
      "    return quotes\n",
      "    \n",
      "    \n",
      "unique_quotes = critics\n",
      " \n",
      "unique_quotes['tokens'] = unique_quotes.quote.apply(tokenize_quote, remove_stop=True)\n",
      "\n",
      "unique_quotes.head()\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>critic</th>\n",
        "      <th>fresh</th>\n",
        "      <th>imdb</th>\n",
        "      <th>publication</th>\n",
        "      <th>quote</th>\n",
        "      <th>review_date</th>\n",
        "      <th>rtid</th>\n",
        "      <th>title</th>\n",
        "      <th>tokens</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>        Derek Adams</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>       Time Out</td>\n",
        "      <td> So ingenious in concept, design and execution ...</td>\n",
        "      <td> 2009-10-04</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "      <td> [ingenious, concept, design, execution, could,...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>    Richard Corliss</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>  TIME Magazine</td>\n",
        "      <td>                 The year's most inventive comedy.</td>\n",
        "      <td> 2008-08-31</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "      <td>                        [years, inventive, comedy]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>        David Ansen</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>       Newsweek</td>\n",
        "      <td> A winning animated feature that has something ...</td>\n",
        "      <td> 2008-08-18</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "      <td> [winning, animated, feature, something, everyo...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>      Leonard Klady</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>        Variety</td>\n",
        "      <td> The film sports a provocative and appealing st...</td>\n",
        "      <td> 2008-06-09</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "      <td> [film, sports, provocative, appealing, story, ...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> Jonathan Rosenbaum</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td> Chicago Reader</td>\n",
        "      <td> An entertaining computer-generated, hyperreali...</td>\n",
        "      <td> 2008-03-10</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "      <td> [entertaining, computergenerated, hyperrealist...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 79,
       "text": [
        "               critic  fresh    imdb     publication                                              quote review_date  rtid      title                                             tokens\n",
        "0         Derek Adams  fresh  114709        Time Out  So ingenious in concept, design and execution ...  2009-10-04  9559  Toy story  [ingenious, concept, design, execution, could,...\n",
        "1     Richard Corliss  fresh  114709   TIME Magazine                  The year's most inventive comedy.  2008-08-31  9559  Toy story                         [years, inventive, comedy]\n",
        "2         David Ansen  fresh  114709        Newsweek  A winning animated feature that has something ...  2008-08-18  9559  Toy story  [winning, animated, feature, something, everyo...\n",
        "3       Leonard Klady  fresh  114709         Variety  The film sports a provocative and appealing st...  2008-06-09  9559  Toy story  [film, sports, provocative, appealing, story, ...\n",
        "4  Jonathan Rosenbaum  fresh  114709  Chicago Reader  An entertaining computer-generated, hyperreali...  2008-03-10  9559  Toy story  [entertaining, computergenerated, hyperrealist..."
       ]
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Sorry I am running out of time. If given more time, I would do re.sub on the tokens then run different regressions. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Question 3: What else is in the quote that we could identify and replace more easily?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import cross_validation\n",
      "\n",
      "xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(x, y, test_size=20, random_state=1234)\n",
      "clf = naive_bayes.MultinomialNB().fit(xtrain, ytrain)\n",
      "# Review errors\n",
      "prob = clf.predict_proba(x)[:, 0]\n",
      "bad_rotten = np.argsort(prob[y == 0])[:15] #we pull out the wrongs for rotten\n",
      "bad_fresh = np.argsort(prob[y == 1])[-15:] # then pull out the wrongs for fresh\n",
      "#.argsort returns the indecices. pulling out the indecies when y ==0 or 1\n",
      "\n",
      "print \"Mis-predicted Rotten quotes\"\n",
      "print '---------------------------'\n",
      "for row in bad_rotten:\n",
      "    print critics[y == 0].quote.irow(row)\n",
      "    print\n",
      "\n",
      "print \"Mis-predicted Fresh quotes\"\n",
      "print '--------------------------'\n",
      "for row in bad_fresh:\n",
      "    print critics[y == 1].quote.irow(row)\n",
      "    print\n",
      "  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Mis-predicted Rotten quotes\n",
        "---------------------------\n",
        "One of the sleaziest movies of the year and certainly the most unpleasant.\n",
        "\n",
        "Working from an Elmore Leonard novel, Tarantino has created a gangster fiction that is never larger than life and sometimes smaller.\n",
        "\n",
        "Stigmata is possibly the funniest movie ever made about Catholicism.\n",
        "\n",
        "It's a fun time at the movies.\n",
        "\n",
        "The hip, smart yarn has a bite not seen in American movies since The War of the Roses.\n",
        "\n",
        "She's All That is not a great movie, but it has its moments.\n",
        "\n",
        "One of the more homely Disney animated features.\n",
        "\n",
        "Superstar may not be the most unnecessary movie of the year, but it's got to rank right up there.\n",
        "\n",
        "One of the cheesiest movies ever made.\n",
        "\n",
        "Where the Wild Things Are is audacious in its refusal to be reassuring, which makes it hard to love, but also hard to dismiss.\n",
        "\n",
        "This is one of the summer's sorrier excuses for a major-studio release.\n",
        "\n",
        "The Waterboy is arguably Sandler's most enjoyable motion picture to date, but it's still far from a masterpiece.\n",
        "\n",
        "The best shot in this film is the first one. Not a good sign.\n",
        "\n",
        "One of the most indecently bad movies of the year.\n",
        "\n",
        "A crude piece of work, spottily acted and directed.\n",
        "\n",
        "Mis-predicted Fresh quotes\n",
        "--------------------------\n",
        "Mark Hamill is particularly good in this film.\n",
        "\n",
        "The picture is a case study.\n",
        "\n",
        "'Once Upon a Time...' now looks like an over-cooked mess of style, metaphor and reference.\n",
        "\n",
        "Empty at the core but superficially diverting.\n",
        "\n",
        "Isn't so much a movie as an overly long pilot episode of some new \"Must See TV'' sitcom.\n",
        "\n",
        "Nobody, I think, will complain that it doesn't have enough action.\n",
        "\n",
        "Supernova, though predictable, isn't half bad."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Total Recall is too much -- but it's too much of a good thing.\n",
        "\n",
        "Things might be bad, the movie suggests, but they're not so bad you can't laugh.\n",
        "\n",
        "Though the script is predictable, it's not too clumsy.\n",
        "\n",
        "The film doesn't seem to have much of a focus. But it doesn't seem to want one, either.\n",
        "\n",
        "A string of hummable songs gives it momentum, Gray's admirably straight-faced narrator holds it together, and a run on black lingerie takes care of almost everything else.\n",
        "\n",
        "The jokes are pretty good, the premise is just off-the-wall enough to keep you tittering.\n",
        "\n",
        "The story is risible, the direction routine, the underlying ethic highly questionable; but the flying stirs the blood like speed.\n",
        "\n",
        "Ooky the Addamses may be, subversive they ain't; it plays like a paean to the nuclear family.\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "From the above quotes, we can see that some quotes may have been mislabelled. \n",
      "\n",
      "For example, \"It's a fun time at the movies.\" in \"Mis-predicted Rotten quotes\" probably was just mislabelled. Clearly, it's a fresh quote and does not belong to rotten. Some quotes such as \"That is not a great movie, but it has its moments.\" are not misplaced. They have both positive and negative languges. If given more time, I would go through the misplaced quote list to see which one is mislabeled, and use setiment analysis to find out the score for each quote."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#learn statistics\n",
      "\n",
      "http://www-bcf.usc.edu/~gareth/ISL/\n",
      "\n",
      "http://www.dataschool.io/15-hours-of-expert-machine-learning-videos/\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}