{
 "metadata": {
  "name": "",
  "signature": "sha256:1d3d56903980c29018582c83add92d8dc32dcce609b0cfa043bf8f732bb74095"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Assignment 3\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sklearn.feature_selection.f_classif(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Import data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "from sklearn import naive_bayes\n",
      "\n",
      "pd.set_option('display.width', 500)\n",
      "pd.set_option('display.max_columns', 30)\n",
      "\n",
      "critics = pd.read_csv('../data/rt_critics.csv')\n",
      "critics.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>critic</th>\n",
        "      <th>fresh</th>\n",
        "      <th>imdb</th>\n",
        "      <th>publication</th>\n",
        "      <th>quote</th>\n",
        "      <th>review_date</th>\n",
        "      <th>rtid</th>\n",
        "      <th>title</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>        Derek Adams</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>       Time Out</td>\n",
        "      <td> So ingenious in concept, design and execution ...</td>\n",
        "      <td> 2009-10-04</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>    Richard Corliss</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>  TIME Magazine</td>\n",
        "      <td>                 The year's most inventive comedy.</td>\n",
        "      <td> 2008-08-31</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>        David Ansen</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>       Newsweek</td>\n",
        "      <td> A winning animated feature that has something ...</td>\n",
        "      <td> 2008-08-18</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>      Leonard Klady</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>        Variety</td>\n",
        "      <td> The film sports a provocative and appealing st...</td>\n",
        "      <td> 2008-06-09</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> Jonathan Rosenbaum</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td> Chicago Reader</td>\n",
        "      <td> An entertaining computer-generated, hyperreali...</td>\n",
        "      <td> 2008-03-10</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "               critic  fresh    imdb     publication                                              quote review_date  rtid      title\n",
        "0         Derek Adams  fresh  114709        Time Out  So ingenious in concept, design and execution ...  2009-10-04  9559  Toy story\n",
        "1     Richard Corliss  fresh  114709   TIME Magazine                  The year's most inventive comedy.  2008-08-31  9559  Toy story\n",
        "2         David Ansen  fresh  114709        Newsweek  A winning animated feature that has something ...  2008-08-18  9559  Toy story\n",
        "3       Leonard Klady  fresh  114709         Variety  The film sports a provocative and appealing st...  2008-06-09  9559  Toy story\n",
        "4  Jonathan Rosenbaum  fresh  114709  Chicago Reader  An entertaining computer-generated, hyperreali...  2008-03-10  9559  Toy story"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Given the text and classifier above, there is still **plenty** we can do to work through data cleanup and improve the model.\n",
      "\n",
      "1. Consider feature selection here: we haven't dropped a single feature! How could we evaluate this process? (check out `f_classif`)\n",
      "2. Last class we experiments with nltk and the part of speach tagger. Consider replacing words with parts of speach instead (using the default tagger), or other text processing tools (remove the stopwords... or just keep the stopwords!)\n",
      "3. What else is in the quote that we could identify and replace more easily?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Vectorizing with SK-Learn"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "CountVectorizer?\n",
      "vectorizer = CountVectorizer(ngram_range=(1,2)) \n",
      "\n",
      "rotten_vectorizer = vectorizer.fit(critics.quote) #going across all the quotes in the quote column\n",
      "x = vectorizer.fit_transform(critics.quote)  #refit & returns back our sparse matrix. \n",
      "y = (critics.fresh == 'fresh').values.astype(int) \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "numpy.ndarray"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_selection.f_classif(x, y)\n",
      "#the first array is the F value, second array is the P value\n",
      "#should i remove the column y? since this is bayes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 45,
       "text": [
        "(array([ 0.77228345,  1.57782629,  1.57782629, ...,  1.57782629,\n",
        "         1.57782629,  1.57782629]),\n",
        " array([ 0.37952658,  0.20909493,  0.20909493, ...,  0.20909493,\n",
        "         0.20909493,  0.20909493]))"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#from sklearn import feature_selection as f_select\n",
      "from sklearn import cross_validation as cv\n",
      "\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "from sklearn import datasets, svm\n",
      "from sklearn.feature_selection import SelectPercentile, f_classif\n",
      "from sklearn import feature_selection as f_select\n",
      "\n",
      "\n",
      "x_columns = list(critics.columns)\n",
      "y_column = 'fresh'\n",
      "x_columns.remove(y_column)\n",
      "\n",
      "significant_columns = []\n",
      "fvals = []\n",
      "for feature in x_columns:\n",
      "    fval, pval = f_select.f_classif(x, y)\n",
      "    print fval, pval\n",
      "    print fval\n",
      "    if pval < 0.05:\n",
      "        significant_columns.append(feature)\n",
      "        fvals.append(fval)\n",
      "\n",
      "print fvals\n",
      "\n",
      "xtrain, xtest, ytrain, ytest = cv.train_test_split(critics[significant_columns], \n",
      "                                                       critics[y_column],\n",
      "                                                       test_size=0.333,\n",
      "                                                       random_state=1234)\n",
      "\n",
      "clf = naive_bayes.BernoulliNB().fit(xtrain, ytrain)\n",
      "\n",
      "print pd.DataFrame({\n",
      "    'column': significant_columns,\n",
      "    #'coef': clf.coef_,\n",
      "    'f-value': fvals,\n",
      "}).set_index('column')\n",
      "\n",
      "\n",
      "training_accuracy = clf.score(xtrain, ytrain)\n",
      "test_accuracy = clf.score(xtest, ytest)\n",
      "\n",
      "\n",
      "%matplotlib inline\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "\n",
      "f = plt.figure(figsize=(7, 5))\n",
      "ax = f.add_subplot(111)\n",
      "ax.hist(fvals)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.77228345  1.57782629  1.57782629 ...,  1.57782629  1.57782629\n",
        "  1.57782629] [ 0.37952658  0.20909493  0.20909493 ...,  0.20909493  0.20909493\n",
        "  0.20909493]\n",
        "[ 0.77228345  1.57782629  1.57782629 ...,  1.57782629  1.57782629\n",
        "  1.57782629]\n"
       ]
      },
      {
       "ename": "ValueError",
       "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-76-8ea91f06354f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mfval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mfval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mpval\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0msignificant_columns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mfvals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Question 2 Last class we experiments with nltk and the part of speach tagger. Consider replacing words with parts of speach instead (using the default tagger), or other text processing tools (remove the stopwords... or just keep the stopwords!)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "\n",
      "def tokenize_quote(q, remove_stop=True):\n",
      "    import string\n",
      "    import re\n",
      "    quote = q\n",
      "    quote = quote.lower()\n",
      "    quote = quote.translate(string.maketrans(\"\",\"\"), string.punctuation)\n",
      "    quotes = nltk.tokenize.wordpunct_tokenize(quote)\n",
      "    \n",
      "    if remove_stop:\n",
      "        stopwords_filter = set(nltk.corpus.stopwords.words('english'))\n",
      "        quotes = [quote for quote in quotes if quote not in stopwords_filter]\n",
      "    \n",
      "unique_quotes = critics\n",
      " \n",
      "unique_quotes['tokens'] = unique_quotes.quote.apply(tokenize_quote, remove_stop=True)\n",
      "unique_quotes['tokens_w_stopwords'] = unique_quotes.quote.apply(tokenize_quote, remove_stop=False)\n",
      "\n",
      "unique_quotes['tokens']\n",
      "unique_quotes['tokens_w_stopwords'] "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 85,
       "text": [
        "0     None\n",
        "1     None\n",
        "2     None\n",
        "3     None\n",
        "4     None\n",
        "5     None\n",
        "6     None\n",
        "7     None\n",
        "8     None\n",
        "9     None\n",
        "10    None\n",
        "11    None\n",
        "12    None\n",
        "13    None\n",
        "14    None\n",
        "...\n",
        "14057    None\n",
        "14058    None\n",
        "14059    None\n",
        "14060    None\n",
        "14061    None\n",
        "14062    None\n",
        "14063    None\n",
        "14064    None\n",
        "14065    None\n",
        "14066    None\n",
        "14067    None\n",
        "14068    None\n",
        "14069    None\n",
        "14070    None\n",
        "14071    None\n",
        "Name: tokens_w_stopwords, Length: 14072, dtype: object"
       ]
      }
     ],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}